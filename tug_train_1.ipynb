{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import datetime\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kick_nan(x):\n",
    "    x = str(x).replace(\" \", \"\").lower()\n",
    "    if (x == \"nan\") or (x == \"免引水\"):\n",
    "        y = 0\n",
    "    else:\n",
    "        y = x\n",
    "    return y\n",
    "\n",
    "def get_dummy_column_wanted(df, all_col=[]):\n",
    "    if len(all_col) > 0:\n",
    "        for i in all_col:\n",
    "            df = pd.concat([df, pd.get_dummies(df[i], prefix=[i])], axis=1)\n",
    "        return df\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def make_col_be_str(df, str_col=[]):\n",
    "    if len(str_col) > 0:\n",
    "        for i in str_col:\n",
    "            df[i] = df[i].apply(lambda x:str(x))\n",
    "        return df\n",
    "    else:\n",
    "        return df\n",
    "        \n",
    "def make_col_be_int(df, int_col=[]):\n",
    "    if len(int_col) > 0:\n",
    "        for i in int_col:\n",
    "            df[i] = df[i].apply(lambda x:int(float(str(x))))\n",
    "        return df\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def make_col_be_float(df, float_col=[]):\n",
    "    if len(float_col) > 0:\n",
    "        for i in float_col:\n",
    "            df[i] = df[i].apply(lambda x:float(str(x)))\n",
    "        return df\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "def data_cleaning():\n",
    "    df = pd.read_excel(\"khh1005.xlsx\")\n",
    "    \n",
    "    # drop useless columns\n",
    "    df[\"work_time\"] = df[\"mean_work_time\"]\n",
    "    df = df.drop([\"min_work_time\", \"max_work_time\", \"mean_work_time\", \"pilot_ready_time\", \"min_end_time\", \"max_end_time\", \"pilot_ready_time\", \"place1\", \"pilot2\", \"tug2_no\", \"tug3_no\", \"pier_info\", \"seven\", \"day\"], axis=1)\n",
    "    df = df[df[\"work_time\"]>0]\n",
    "    \n",
    "    # fix the err data (kick out nan)\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x:str(kick_nan(x)))\n",
    "    \n",
    "    # add features of the month, hour, year\n",
    "    df[\"month\"] = df[\"start_time\"].apply(lambda x: int(str(x).replace(\"-\", \"\").replace(\":\", \"\")[4:6]))\n",
    "    df[\"day\"] = df[\"start_time\"].apply(lambda x: int(str(x).replace(\"-\", \"\").replace(\":\", \"\")[6:8]))\n",
    "    df[\"hour\"] = df[\"start_time\"].apply(lambda x: int(str(x).replace(\"-\", \"\").replace(\":\", \"\")[8:10]))\n",
    "    df[\"weekday\"] = df[\"start_time\"].apply(lambda x: int(datetime.datetime.strptime(str(x), \"%Y-%m-%d%H:%M:%S\").weekday()))\n",
    "    \n",
    "    # the datatype should be float, string, and integer\n",
    "    df = make_col_be_float(df, ['front_weight','back_weight','weight_level','dist','wind'])\n",
    "    df = make_col_be_str(df, ['sailing_status','park','reverse']) #,'start_time'\n",
    "    df = make_col_be_int(df, ['pilot_wait_time', 'work_time', 'ship_no','port','place2','pilot1','tug1_no','tug_cnt','total_weight','avg_hp']) #, \"month\", \"day\", \"hour\"\n",
    "    \n",
    "    # drop useless columns\n",
    "    df = df.drop([\"start_time\"], axis=1)\n",
    "    \n",
    "    # drop row with missing data\n",
    "    df = df[(df.port != 0) & (df.port != 3)]\n",
    "    df = df[(df.park != \"0\")]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the df: (31178, 22)\n",
      "--------------------------------------------------------------------------------\n",
      "column names: Index(['ship_no', 'sailing_status', 'pilot_wait_time', 'port', 'place2',\n",
      "       'pilot1', 'tug1_no', 'tug_cnt', 'total_weight', 'front_weight',\n",
      "       'back_weight', 'weight_level', 'dist', 'wind', 'park', 'reverse',\n",
      "       'avg_hp', 'work_time', 'month', 'day', 'hour', 'weekday'],\n",
      "      dtype='object')\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ship_no</th>\n",
       "      <th>sailing_status</th>\n",
       "      <th>pilot_wait_time</th>\n",
       "      <th>port</th>\n",
       "      <th>place2</th>\n",
       "      <th>pilot1</th>\n",
       "      <th>tug1_no</th>\n",
       "      <th>tug_cnt</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>front_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>dist</th>\n",
       "      <th>wind</th>\n",
       "      <th>park</th>\n",
       "      <th>reverse</th>\n",
       "      <th>avg_hp</th>\n",
       "      <th>work_time</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50091</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1066</td>\n",
       "      <td>100</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>6094</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4968.093286</td>\n",
       "      <td>0.15</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>3200</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>308684</td>\n",
       "      <td>i</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1058</td>\n",
       "      <td>82</td>\n",
       "      <td>321</td>\n",
       "      <td>1</td>\n",
       "      <td>16232</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3879.059264</td>\n",
       "      <td>1.00</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>3200</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46698</td>\n",
       "      <td>i</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1079</td>\n",
       "      <td>74</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>27968</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1502.675679</td>\n",
       "      <td>1.00</td>\n",
       "      <td>l</td>\n",
       "      <td>0</td>\n",
       "      <td>5200</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>326585</td>\n",
       "      <td>i</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1102</td>\n",
       "      <td>102</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>8562</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2785.267130</td>\n",
       "      <td>0.75</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>3700</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57126</td>\n",
       "      <td>i</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1109</td>\n",
       "      <td>98</td>\n",
       "      <td>172</td>\n",
       "      <td>2</td>\n",
       "      <td>108069</td>\n",
       "      <td>11.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1033.162198</td>\n",
       "      <td>0.75</td>\n",
       "      <td>r</td>\n",
       "      <td>0</td>\n",
       "      <td>5200</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ship_no sailing_status  pilot_wait_time  port  place2  pilot1  tug1_no  \\\n",
       "0    50091              o                0     1    1066     100      109   \n",
       "1   308684              i                4     1    1058      82      321   \n",
       "2    46698              i                8     2    1079      74      171   \n",
       "3   326585              i                5     2    1102     102      163   \n",
       "4    57126              i                5     2    1109      98      172   \n",
       "\n",
       "   tug_cnt  total_weight  front_weight   ...            dist  wind  park  \\\n",
       "0        1          6094           6.0   ...     4968.093286  0.15     o   \n",
       "1        1         16232           6.0   ...     3879.059264  1.00     o   \n",
       "2        1         27968          10.0   ...     1502.675679  1.00     l   \n",
       "3        2          8562           4.0   ...     2785.267130  0.75     o   \n",
       "4        2        108069          11.5   ...     1033.162198  0.75     r   \n",
       "\n",
       "   reverse avg_hp work_time  month  day  hour  weekday  \n",
       "0        0   3200         4      1    1     0        6  \n",
       "1        0   3200        52      1    1     1        6  \n",
       "2        0   5200        27      1    1     1        6  \n",
       "3        0   3700        34      1    1     2        6  \n",
       "4        0   5200        26      1    1     2        6  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_cleaning()\n",
    "print(\"shape of the df:\", df.shape)\n",
    "print(\"-\"*80)\n",
    "print(\"column names:\", df.columns)\n",
    "print(\"-\"*80)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_before_train(df, dm_col, dp_col, pr_col, target_y_c, target_y_r):\n",
    "    y_c = df[target_y_c]\n",
    "    y_r = df[target_y_r]\n",
    "    if dm_col != []:\n",
    "        df = get_dummy_column_wanted(df, dm_col)\n",
    "    else:\n",
    "        df = df\n",
    "\n",
    "    if dp_col+dm_col != []:\n",
    "        x = df.drop(dp_col+dm_col, axis=1)\n",
    "    else:\n",
    "        x = df.drop([target_y_c, target_y_r], axis=1)\n",
    "    print(x.columns)\n",
    "    X_train, X_test, y_train_c, y_test_c = train_test_split(x, y_c, test_size=0.2, random_state=101)\n",
    "    y_train_r, y_test_r = X_train[target_y_r], X_test[target_y_r]\n",
    "    X_train, X_test = X_train.drop(target_y_r, axis=1), X_test.drop(target_y_r, axis=1)\n",
    " \n",
    "    return X_train, X_test, y_train_c, y_test_c, y_train_r, y_test_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# processing for status_sailing equal to \"i\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of df_1 (14981, 22)\n",
      "====================================================================================================\n",
      "          work_time\n",
      "count  14759.000000\n",
      "mean      35.605529\n",
      "std       10.451598\n",
      "min        9.000000\n",
      "25%       27.000000\n",
      "50%       35.000000\n",
      "75%       43.000000\n",
      "max       65.000000\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "df_1 = df[(df[\"sailing_status\"] == \"i\")]\n",
    "print(\"the shape of df_1\", df_1.shape)\n",
    "print(\"=\"*100)\n",
    "\n",
    "# remove outlier\n",
    "df_1_bl_p2std = int(np.mean(df_1.work_time) + np.std(df_1.work_time)*2)+1\n",
    "df_1_bl_n2std = int(np.mean(df_1.work_time) - np.std(df_1.work_time)*2)+1\n",
    "df_1 = df_1[(df_1.work_time<=df_1_bl_p2std) & (df_1_bl_n2std<df_1.work_time)]\n",
    "\n",
    "print(df_1[[\"work_time\"]].describe())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['total_weight', 'weight_level', 'dist', 'wind', 'avg_hp', 'work_time',\n",
      "       '['port']_1', '['port']_2', '['tug_cnt']_1', '['tug_cnt']_2',\n",
      "       '['tug_cnt']_3', '['park']_l', '['park']_o', '['park']_r',\n",
      "       '['reverse']_0', '['reverse']_1', '['month']_1', '['month']_2',\n",
      "       '['month']_3', '['month']_4', '['month']_5', '['month']_6',\n",
      "       '['month']_7', '['month']_8', '['month']_9', '['month']_10',\n",
      "       '['month']_11', '['month']_12', '['hour']_0', '['hour']_1',\n",
      "       '['hour']_2', '['hour']_3', '['hour']_4', '['hour']_5', '['hour']_6',\n",
      "       '['hour']_7', '['hour']_8', '['hour']_9', '['hour']_10', '['hour']_11',\n",
      "       '['hour']_12', '['hour']_13', '['hour']_14', '['hour']_15',\n",
      "       '['hour']_16', '['hour']_17', '['hour']_18', '['hour']_19',\n",
      "       '['hour']_20', '['hour']_21', '['hour']_22', '['hour']_23',\n",
      "       '['weekday']_0', '['weekday']_1', '['weekday']_2', '['weekday']_3',\n",
      "       '['weekday']_4', '['weekday']_5', '['weekday']_6'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_1_med = df_1[\"work_time\"].median()\n",
    "dm_col_1c = [\"port\", \"tug_cnt\", \"park\", \"reverse\", \"month\", \"hour\", \"weekday\"]\n",
    "dp_col_1c = [\"front_weight\", \"back_weight\", \"tug1_no\", \"pilot1\", \"ship_no\", \"sailing_status\", \"place2\", \"day\", \"work_time_med\", \"pilot_wait_time\"]\n",
    "pr_col_1c = []\n",
    "df_1[\"work_time_med\"] = df_1[\"work_time\"].apply(lambda x: 0 if x<=df_1_med else 1)\n",
    "X1_train, X1_test, y1_train_c, y1_test_c, y1_train_r, y1_test_r = \\\n",
    "    pre_processing_before_train(df_1, dm_col_1c, dp_col_1c, pr_col_1c, \"work_time_med\", \"work_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11807, 58)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# processing for status_sailing equal to \"t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of df_2 (1284, 22)\n",
      "====================================================================================================\n",
      "         work_time\n",
      "count  1242.000000\n",
      "mean     43.512077\n",
      "std      13.898803\n",
      "min       5.000000\n",
      "25%      35.000000\n",
      "50%      40.000000\n",
      "75%      50.000000\n",
      "max      91.000000\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "df_2 = df[(df[\"sailing_status\"] == \"t\")]\n",
    "print(\"the shape of df_2\", df_2.shape)\n",
    "print(\"=\"*100)\n",
    "\n",
    "# remove outlier\n",
    "df_2_bl_p2std = int(np.mean(df_2.work_time) + np.std(df_2.work_time)*2)+1\n",
    "# df_2_bl_n2std = int(np.mean(df_2.work_time) - np.std(df_2.work_time)*2)+1\n",
    "df_2 = df_2[(df_2.work_time<=df_2_bl_p2std)]\n",
    "\n",
    "print(df_2[[\"work_time\"]].describe())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['total_weight', 'weight_level', 'dist', 'wind', 'avg_hp', 'work_time',\n",
      "       '['port']_1', '['port']_2', '['tug_cnt']_1', '['tug_cnt']_2',\n",
      "       '['tug_cnt']_3', '['park']_l', '['park']_o', '['park']_r',\n",
      "       '['reverse']_0', '['reverse']_1', '['month']_1', '['month']_2',\n",
      "       '['month']_3', '['month']_4', '['month']_5', '['month']_6',\n",
      "       '['month']_7', '['month']_8', '['month']_9', '['month']_10',\n",
      "       '['month']_11', '['month']_12', '['hour']_0', '['hour']_1',\n",
      "       '['hour']_2', '['hour']_3', '['hour']_4', '['hour']_5', '['hour']_6',\n",
      "       '['hour']_7', '['hour']_8', '['hour']_9', '['hour']_10', '['hour']_11',\n",
      "       '['hour']_12', '['hour']_13', '['hour']_14', '['hour']_15',\n",
      "       '['hour']_16', '['hour']_17', '['hour']_18', '['hour']_19',\n",
      "       '['hour']_20', '['hour']_21', '['hour']_22', '['hour']_23',\n",
      "       '['weekday']_0', '['weekday']_1', '['weekday']_2', '['weekday']_3',\n",
      "       '['weekday']_4', '['weekday']_5', '['weekday']_6'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_2_med = df_2[\"work_time\"].median()\n",
    "dm_col_2c = [\"port\", \"tug_cnt\", \"park\",\"reverse\", \"month\", \"hour\", \"weekday\"]\n",
    "dp_col_2c = [\"front_weight\", \"back_weight\", \"ship_no\", \"pilot1\", \"sailing_status\", \"place2\", \"day\", \"work_time_med\", \"tug1_no\", \"pilot_wait_time\"]\n",
    "pr_col_2c = []\n",
    "df_2[\"work_time_med\"] = df_2[\"work_time\"].apply(lambda x: 0 if x<=df_2_med else 1)\n",
    "X2_train, X2_test, y2_train_c, y2_test_c, y2_train_r, y2_test_r = \\\n",
    "    pre_processing_before_train(df_2, dm_col_2c, dp_col_2c, pr_col_2c, \"work_time_med\", \"work_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(993, 58)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# processing for status_sailing equal to \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of df_3 (14913, 22)\n",
      "====================================================================================================\n",
      "          work_time\n",
      "count  14259.000000\n",
      "mean      15.424434\n",
      "std        8.305709\n",
      "min        1.000000\n",
      "25%       10.000000\n",
      "50%       15.000000\n",
      "75%       20.000000\n",
      "max       38.000000\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "df_3 = df[(df[\"sailing_status\"] == \"o\")]\n",
    "print(\"the shape of df_3\", df_3.shape)\n",
    "print(\"=\"*100)\n",
    "\n",
    "# remove outlier\n",
    "df_3_bl_p2std = int(np.mean(df_3.work_time) + np.std(df_3.work_time)*2)+1\n",
    "# df_3_bl_n2std = int(np.mean(df_3.work_time) - np.std(df_3.work_time)*2)+1\n",
    "df_3 = df_3[(df_3.work_time<=df_3_bl_p2std)]\n",
    "\n",
    "print(df_3[[\"work_time\"]].describe())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['total_weight', 'weight_level', 'dist', 'wind', 'avg_hp', 'work_time',\n",
      "       '['port']_1', '['port']_2', '['tug_cnt']_1', '['tug_cnt']_2',\n",
      "       '['tug_cnt']_3', '['park']_l', '['park']_o', '['park']_r',\n",
      "       '['reverse']_0', '['reverse']_1', '['month']_1', '['month']_2',\n",
      "       '['month']_3', '['month']_4', '['month']_5', '['month']_6',\n",
      "       '['month']_7', '['month']_8', '['month']_9', '['month']_10',\n",
      "       '['month']_11', '['month']_12', '['hour']_0', '['hour']_1',\n",
      "       '['hour']_2', '['hour']_3', '['hour']_4', '['hour']_5', '['hour']_6',\n",
      "       '['hour']_7', '['hour']_8', '['hour']_9', '['hour']_10', '['hour']_11',\n",
      "       '['hour']_12', '['hour']_13', '['hour']_14', '['hour']_15',\n",
      "       '['hour']_16', '['hour']_17', '['hour']_18', '['hour']_19',\n",
      "       '['hour']_20', '['hour']_21', '['hour']_22', '['hour']_23',\n",
      "       '['weekday']_0', '['weekday']_1', '['weekday']_2', '['weekday']_3',\n",
      "       '['weekday']_4', '['weekday']_5', '['weekday']_6'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_3_med = df_3[\"work_time\"].median()\n",
    "dm_col_3c = [\"port\", \"tug_cnt\", \"park\", \"reverse\", \"month\", \"hour\", \"weekday\"]\n",
    "dp_col_3c = [\"front_weight\", \"back_weight\", \"pilot1\", \"tug1_no\", \"ship_no\", \"sailing_status\", \"place2\", \"day\", \"work_time_med\", \"pilot_wait_time\"]\n",
    "#pr_col_3c = [\"total_weight\", \"dist\", \"weight_level\", \"wind\", \"avg_hp\"]\n",
    "pr_col_3c = []\n",
    "df_3[\"work_time_med\"] = df_3[\"work_time\"].apply(lambda x: 0 if x<=df_3_med else 1)\n",
    "X3_train, X3_test, y3_train_c, y3_test_c, y3_train_r, y3_test_r = \\\n",
    "    pre_processing_before_train(df_3, dm_col_3c, dp_col_3c, pr_col_3c, \"work_time_med\", \"work_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11407, 58)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Classification (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=40, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=20,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define regression model\n",
    "clf1 = RandomForestClassifier(max_depth=40, n_estimators=200,random_state=0, n_jobs=20)\n",
    "clf2 = RandomForestClassifier(max_depth=40, n_estimators=200,random_state=0, n_jobs=20)\n",
    "clf3 = RandomForestClassifier(max_depth=40, n_estimators=200,random_state=0, n_jobs=20)\n",
    "\n",
    "# Train regression model\n",
    "clf1.fit(X1_train, y1_train_c)\n",
    "clf2.fit(X2_train, y2_train_c)\n",
    "clf3.fit(X3_train, y3_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for df_1 classification 0.8275745257452575\n",
      "accuracy for df_2 classification 0.7349397590361446\n",
      "accuracy for df_3 classification 0.7784011220196353\n"
     ]
    }
   ],
   "source": [
    "# check accuracy\n",
    "accuracy1 = metrics.accuracy_score(y1_test_c, clf1.predict(X1_test))\n",
    "print(\"accuracy for df_1 classification\", accuracy1)\n",
    "accuracy2 = metrics.accuracy_score(y2_test_c, clf2.predict(X2_test))\n",
    "print(\"accuracy for df_2 classification\", accuracy2)\n",
    "accuracy3 = metrics.accuracy_score(y3_test_c, clf3.predict(X3_test))\n",
    "print(\"accuracy for df_3 classification\", accuracy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "with open('model_new/clf_1.pickle', 'wb') as f1:\n",
    "    pickle.dump(clf1,f1)\n",
    "with open('model_new/clf_2.pickle', 'wb') as f2:\n",
    "    pickle.dump(clf2,f2)\n",
    "with open('model_new/clf_3.pickle', 'wb') as f3:\n",
    "    pickle.dump(clf3,f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Regression (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "regr1_0 = RandomForestRegressor(max_depth=25, random_state=0,n_estimators=100, n_jobs=10)\n",
    "regr2_0 = RandomForestRegressor(max_depth=30, random_state=0,n_estimators=200, n_jobs=10)\n",
    "regr3_0 = RandomForestRegressor(max_depth=50, random_state=0,n_estimators=100, n_jobs=10)\n",
    "regr1_1 = RandomForestRegressor(max_depth=25, random_state=0,n_estimators=100, n_jobs=10)\n",
    "regr2_1 = RandomForestRegressor(max_depth=30, random_state=0,n_estimators=200, n_jobs=10)\n",
    "regr3_1 = RandomForestRegressor(max_depth=50, random_state=0,n_estimators=100, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict training data by classification model to know each row is higher or lower than median\n",
    "pred1_train = clf1.predict(X1_train)\n",
    "pred2_train = clf2.predict(X2_train)\n",
    "pred3_train = clf3.predict(X3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=50,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=10,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train regression model\n",
    "regr1_0.fit( X1_train[pred1_train==0] , y1_train_r[pred1_train==0])\n",
    "regr1_1.fit( X1_train[pred1_train==1] , y1_train_r[pred1_train==1])\n",
    "regr2_0.fit( X2_train[pred2_train==0] , y2_train_r[pred2_train==0])\n",
    "regr2_1.fit( X2_train[pred2_train==1] , y2_train_r[pred2_train==1])\n",
    "regr3_0.fit( X3_train[pred3_train==0] , y3_train_r[pred3_train==0])\n",
    "regr3_1.fit( X3_train[pred3_train==1] , y3_train_r[pred3_train==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "with open('model_new/reg_1_0.pickle', 'wb') as f:\n",
    "    pickle.dump(regr1_0,f)\n",
    "with open('model_new/reg_1_1.pickle', 'wb') as f:\n",
    "    pickle.dump(regr1_1,f)\n",
    "with open('model_new/reg_2_0.pickle', 'wb') as f:\n",
    "    pickle.dump(regr2_0,f)\n",
    "with open('model_new/reg_2_1.pickle', 'wb') as f:\n",
    "    pickle.dump(regr2_1,f)\n",
    "with open('model_new/reg_3_0.pickle', 'wb') as f:\n",
    "    pickle.dump(regr3_0,f)\n",
    "with open('model_new/reg_3_1.pickle', 'wb') as f:\n",
    "    pickle.dump(regr3_1,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE of three status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict testing data by classification model to know each row is higher or lower than median\n",
    "pred1_c = clf1.predict(X1_test)\n",
    "pred2_c = clf2.predict(X2_test)\n",
    "pred3_c = clf3.predict(X3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status I\n",
      "mae for df_1 <= median: 4.515340206343565\n",
      "mae for df_1 > median: 5.744414705756139\n",
      "status T\n",
      "mae for df_2 <= median: 7.874815950920247\n",
      "mae for df_2 > median: 10.62912343470483\n",
      "status O\n",
      "mae for df_3 <= median: 4.711056622851365\n",
      "mae for df_3 > median: 5.705160183066361\n"
     ]
    }
   ],
   "source": [
    "# MAE of three status (seperated to lower or higher than median for each status)\n",
    "print(\"status I\")\n",
    "print(\"mae for df_1 <= median:\", mean_absolute_error(y1_test_r[pred1_c==0], regr1_0.predict(X1_test[pred1_c==0])))\n",
    "print(\"mae for df_1 > median:\", mean_absolute_error(y1_test_r[pred1_c==1], regr1_1.predict(X1_test[pred1_c==1])))\n",
    "print(\"status T\")\n",
    "print(\"mae for df_2 <= median:\", mean_absolute_error(y2_test_r[pred2_c==0], regr2_0.predict(X2_test[pred2_c==0])))\n",
    "print(\"mae for df_2 > median:\", mean_absolute_error(y2_test_r[pred2_c==1], regr2_1.predict(X2_test[pred2_c==1])))\n",
    "print(\"status O\")\n",
    "print(\"mae for df_3 <= median:\", mean_absolute_error(y3_test_r[pred3_c==0], regr3_0.predict(X3_test[pred3_c==0])))\n",
    "print(\"mae for df_3 > median:\", mean_absolute_error(y3_test_r[pred3_c==1], regr3_1.predict(X3_test[pred3_c==1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE status I: 5.12363215879674\n",
      "MAE status T: 8.826102873030585\n",
      "MAE status O: 5.01570126227209\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE of three status\n",
    "pred_1_0 = regr1_0.predict(X1_test[pred1_c == 0])\n",
    "pred_1_1 = regr1_1.predict(X1_test[pred1_c == 1])\n",
    "pred_1 = np.concatenate((pred_1_0, pred_1_1))\n",
    "test_1 = np.concatenate((y1_test_r[pred1_c==0], y1_test_r[pred1_c==1]))\n",
    "\n",
    "pred_2_0 = regr2_0.predict(X2_test[pred2_c == 0])\n",
    "pred_2_1 = regr2_1.predict(X2_test[pred2_c == 1])\n",
    "pred_2 = np.concatenate((pred_2_0, pred_2_1))\n",
    "test_2 = np.concatenate((y2_test_r[pred2_c==0], y2_test_r[pred2_c==1]))\n",
    "\n",
    "pred_3_0 = regr3_0.predict(X3_test[pred3_c == 0])\n",
    "pred_3_1 = regr3_1.predict(X3_test[pred3_c == 1])\n",
    "pred_3 = np.concatenate((pred_3_0, pred_3_1))\n",
    "test_3 = np.concatenate((y3_test_r[pred3_c==0], y3_test_r[pred3_c==1]))\n",
    "\n",
    "print(\"MAE status I:\", mean_absolute_error(pred_1, test_1))\n",
    "print(\"MAE status T:\", mean_absolute_error(pred_2, test_2))\n",
    "print(\"MAE status O:\", mean_absolute_error(pred_3, test_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
